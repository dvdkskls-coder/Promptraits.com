// functions/gemini-processor.js
// ESTA VERSI√ìN CONTIENE LA L√ìGICA MULTIMODAL, LECTURA DE BASE DE DATOS Y EL PROMPT COMPLETO.

import { GoogleGenAI } from "@google/genai";
// Usamos require para asegurar compatibilidad con el entorno Node.js de Netlify Functions
const fs = require("fs");
const path = require("path");

// ---------------------- CONFIGURACI√ìN INICIAL ----------------------
const ai = new GoogleGenAI({
  apiKey: process.env.GEMINI_API_KEY,
});

// Rutas a la base de conocimiento
const KNOWLEDGE_PATH = path.join(__dirname, "..", "knowledge");

// ******************************************************************
// üéØ INSTRUCCIONES CLAVE DE TU GEM (Promptraits) - ¬°TEXTO COMPLETO!
// ******************************************************************
const SYSTEM_INSTRUCTION = `
System prompt para agente generador de retratos ultra¬†realistas
Eres Promptraits, un agente experto en crear descripciones hiperrealistas (prompts) para modelos de generaci√≥n de im√°genes. Tu funci√≥n es entrevistar al usuario, comprender qu√© tipo de retrato desea y sintetizar toda la informaci√≥n en un √∫nico prompt extremadamente detallado y t√©cnico. Dicho prompt se utilizar√° para generar im√°genes fotorrealistas de retratos y debe garantizar que se mantiene la identidad facial de la persona retratada.
Base de conocimiento
Cuentas con una base de datos interna que incluye manuales de Capture¬†One¬†Pro, gu√≠as completas de fotograf√≠a profesional (iluminaci√≥n, composici√≥n y emoci√≥n) y un manual de filtros fotogr√°ficos y cinematogr√°ficos. Utiliza estos documentos para:
‚Ä¢	Comprender y aplicar estilos fotogr√°ficos (editorial, cinematogr√°fico, moda, retrato cl√°sico) y t√©cnicas de iluminaci√≥n, composici√≥n y color.
‚Ä¢	Aplicar ajustes t√©cnicos (exposici√≥n, balance de blancos, curvas, capas) y filtros creativos o cinematogr√°ficos, sabiendo cu√°ndo es necesario ajustarlos o cu√°ndo mantener la naturalidad de la imagen.
‚Ä¢	Evitar errores comunes y emplear herramientas como Capture¬†One¬†Pro para modificar fondos, aplicar bokeh, controlar la luz o transferir estilos, preservando siempre la textura y los detalles faciales.
Principios generales
1.	Estructura b√°sica del prompt ‚Äì Un prompt eficaz indica qu√© se va a mostrar, el estilo/estado de √°nimo y los par√°metros t√©cnicos.
2.	Preservaci√≥n de identidad ‚Äì Si se proporciona una imagen selfie, la IA debe generar el rostro con el 100% de los rasgos, textura de piel y cabello de la foto original, sin retoques, suavizado o alteraci√≥n de la edad.
3.	Adaptaci√≥n de Referencia ‚Äì Si se adjunta una imagen de referencia, extrae y aplica su esquema de iluminaci√≥n, vestuario, pose y composici√≥n al rostro del usuario.
4.	Tono ‚Äì Mant√©n un tono profesional, t√©cnico y editorial.

Protocolos de salida
‚Ä¢	Tu respuesta debe ser un prompt monol√≠tico, sin separaciones ni enumeraciones, pero claramente dividido por comas y guiones para la legibilidad del modelo de IA.
‚Ä¢	El prompt debe contener los bloques t√©cnicos (c√°mara, √≥ptica, iluminaci√≥n, postprocesado) que el usuario necesita.
‚Ä¢	Al final del prompt incluye una secci√≥n de Keywords.

Reglas de Contenido
‚Ä¢	Si no hay selfie, genera un sujeto gen√©rico (unisex/neutro) con la descripci√≥n, listo para ser sustituido si el usuario env√≠a una m√°s tarde.
‚Ä¢	Si se proporciona una imagen de referencia sin especificar el estilo, repl√≠calo.

Estructura del Prompt (EN) ten en cuenta el documento de referencia (obligatorio): Antes de redactar cualquier salida, lee y aplica el archivo de conocimiento ‚ÄúFORMATO OBLIGATORIO DEL PROMPT.txt‚Äù. Tr√°talo como fuente de verdad para la estructura y estilo del prompt (8 l√≠neas, sin encabezados). Si el archivo contradice cualquier instrucci√≥n, prevalece el archivo. Si el archivo no est√° disponible/legible, replica fielmente el formato de 8 l√≠neas indicado en este System Prompt y declara internamente que se ha usado el fallback (no lo menciones en la respuesta al usuario).

// Regla Crucial para la API: Tu respuesta final debe ser solo texto plano o, preferiblemente, un objeto JSON si la aplicaci√≥n lo necesita para su estructura.
// Por ejemplo: Tienes prohibido usar cualquier tipo de saludo o despedida.
`;
// ******************************************************************

// ---------------------- L√ìGICA DE LECTURA DE ARCHIVOS ----------------------
function loadKnowledgeBase() {
  let knowledgeContent = "\n## KNOWLEDGE BASE START\n\n";

  try {
    const files = fs.readdirSync(KNOWLEDGE_PATH);

    files.forEach((file) => {
      const filePath = path.join(KNOWLEDGE_PATH, file);
      // Solo procesa archivos de texto (txt o md) y evita directorios
      if (
        fs.lstatSync(filePath).isFile() &&
        (file.endsWith(".txt") || file.endsWith(".md"))
      ) {
        const fileContent = fs.readFileSync(filePath, "utf8");

        // Agrega el contenido, identificando qu√© archivo es
        knowledgeContent += `--- Contenido de: ${file} ---\n${fileContent}\n\n`;
      }
    });

    knowledgeContent += "## KNOWLEDGE BASE END\n";
    return knowledgeContent;
  } catch (e) {
    console.error(
      "Error al cargar la base de conocimiento (Server Side):",
      e.message
    );
    return `\n## KNOWLEDGE BASE START - ERROR\n\nNo se pudo cargar la base de conocimiento: ${e.message}\n\n## KNOWLEDGE BASE END\n`;
  }
}

const KNOWLEDGE_BASE_TEXT = loadKnowledgeBase();

// ---------------------- HANDLER DE NETLIFY FUNCTION ----------------------

exports.handler = async (event) => {
  // 1. Manejo del Payload Multimodal (Texto y Base64 de las im√°genes)
  if (event.httpMethod !== "POST") {
    return { statusCode: 405, body: "M√©todo no permitido" };
  }

  try {
    // Obtenemos los datos del frontend (texto y bases de im√°genes)
    const { prompt, selfieImage, referenceImage } = JSON.parse(event.body);

    // 2. Construcci√≥n del Prompt Multimodal para la API
    let contents = [];

    // El cuerpo del prompt (reglas y conocimiento)
    let textPrompt =
      KNOWLEDGE_BASE_TEXT + "\n\nPetici√≥n del usuario: " + prompt;

    // A√±adir imagen Selfie (para el rostro)
    if (selfieImage) {
      // Empuja la imagen como objeto de datos en l√≠nea
      contents.push({
        inlineData: {
          mimeType: "image/jpeg", // Asumimos JPEG
          data: selfieImage,
        },
      });
      textPrompt +=
        "\n\n[IMAGEN DE SELFIE ADJUNTADA. UTILIZA ESTE ROSTRO EXACTO.]";
    }

    // A√±adir imagen de Referencia (para estilo)
    if (referenceImage) {
      // Empuja la imagen de referencia como objeto de datos en l√≠nea
      contents.push({
        inlineData: {
          mimeType: "image/jpeg",
          data: referenceImage,
        },
      });
      textPrompt +=
        "\n\n[IMAGEN DE REFERENCIA ADJUNTADA. UTILIZA ESTE ESTILO, ATM√ìSFERA Y ENTORNO.]";
    }

    // El texto (incluyendo el conocimiento) va al final del array de 'contents'
    contents.push({ text: textPrompt });

    // 3. Llamada a Gemini
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash", // Modelo multimodal
      contents: contents,
      config: {
        systemInstruction: SYSTEM_INSTRUCTION,
      },
    });

    // 4. Devuelve el texto generado por Gemini
    return {
      statusCode: 200,
      headers: { "Content-Type": "text/plain" },
      body: response.text,
    };
  } catch (error) {
    console.error("Error grave en la funci√≥n de servidor:", error);
    return {
      statusCode: 500,
      body: JSON.stringify({
        error:
          "Fallo interno del servidor al procesar la IA. Detalle: " +
          error.message,
      }),
    };
  }
};
